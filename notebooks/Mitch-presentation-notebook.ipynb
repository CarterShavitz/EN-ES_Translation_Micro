{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92710d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install torch transformers datasets evaluate sacrebleu\n",
    "# -*- coding: utf-8 -*-\n",
    "import logging\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "# ─── 1) SETUP LOGGING ──────────────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%Y/%m/%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ─── 2) LOAD & SPLIT EUROPARL EN–ES ────────────────────────────────────────────\n",
    "logger.info(\"Loading Europarl English–Spanish dataset…\")\n",
    "raw = load_dataset(\"europarl_bilingual\", \"en-es\")\n",
    "if \"validation\" not in raw:\n",
    "    logger.info(\"Creating a 10% validation split…\")\n",
    "    split = raw[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "    raw = DatasetDict({\n",
    "        \"train\": split[\"train\"],\n",
    "        \"validation\": split[\"test\"],\n",
    "        \"test\": raw.get(\"test\",\n",
    "                        split[\"train\"].train_test_split(test_size=0.2, seed=42)[\"test\"])\n",
    "    })\n",
    "\n",
    "# ─── 3) SUBSAMPLE FOR SPEED ──────────────────────────────────────────────────\n",
    "max_train, max_val = 30_000, 3_000\n",
    "raw[\"train\"] = raw[\"train\"].select(range(min(len(raw[\"train\"]), max_train)))\n",
    "raw[\"validation\"] = raw[\"validation\"].select(range(min(len(raw[\"validation\"]), max_val)))\n",
    "\n",
    "# ─── 4) TOKENIZER & MODEL ─────────────────────────────────────────────────────\n",
    "MODEL_NAME = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "logger.info(f\"Loading tokenizer and model: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# ─── 5) PREPROCESS FUNCTION ──────────────────────────────────────────────────\n",
    "max_len = 128\n",
    "\n",
    "def preprocess(batch):\n",
    "    inputs = [t[\"en\"] for t in batch[\"translation\"]]\n",
    "    targets = [t[\"es\"] for t in batch[\"translation\"]]\n",
    "    encodings = tokenizer(\n",
    "        inputs, max_length=max_len, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets, max_length=max_len, truncation=True, padding=\"max_length\"\n",
    "        )\n",
    "    encodings[\"labels\"] = labels[\"input_ids\"]\n",
    "    return encodings\n",
    "\n",
    "# ─── 6) FAST TOKENIZATION ─────────────────────────────────────────────────────\n",
    "logger.info(\"Tokenizing dataset with fast mapping…\")\n",
    "tokenized = raw.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=2000,\n",
    "    num_proc=4,\n",
    "    remove_columns=raw[\"train\"].column_names,\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "\n",
    "# ─── 7) DATA COLLATOR ─────────────────────────────────────────────────────────\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, model=model, padding=\"longest\"\n",
    ")\n",
    "\n",
    "# ─── 8) METRICS ───────────────────────────────────────────────────────────────\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(\n",
    "        preds, skip_special_tokens=True\n",
    "    )\n",
    "    decoded_labels = tokenizer.batch_decode(\n",
    "        labels, skip_special_tokens=True\n",
    "    )\n",
    "    result = bleu.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n",
    "    result[\"bleu\"] *= 100\n",
    "    return result\n",
    "\n",
    "# ─── 9) TRAINING ARGUMENTS ────────────────────────────────────────────────────\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    # turn on training & evaluation\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    # run validation every N steps (adjust to match ~1 epoch)\n",
    "    eval_steps=500,\n",
    "    # save a checkpoint every N steps\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "\n",
    "    # hardware / performance\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "\n",
    "    # optimizer & schedule\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    optim=\"adamw_torch\",\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    # logging\n",
    "    logging_steps=100,\n",
    "\n",
    "    # generation\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=max_len,\n",
    ")\n",
    "\n",
    "# ─── 10) TRAINER ─────────────────────────────────────────────────────────────\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# ─── 11) TRAINING ─────────────────────────────────────────────────────────────\n",
    "logger.info(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# ─── 12) EVALUATION ───────────────────────────────────────────────────────────\n",
    "logger.info(\"Evaluating on test set...\")\n",
    "scores = trainer.evaluate(tokenized[\"test\"])\n",
    "logger.info(f\"Test results: {scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f954d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate                : 3e-05\n",
      "Per-device train batch size  : 16\n",
      "Weight decay                 : 0.01\n",
      "Warmup steps                 : 0\n",
      "Num train epochs             : 3\n"
     ]
    }
   ],
   "source": [
    "# Grab the active args\n",
    "args = trainer.args  # or just use training_args if you prefer\n",
    "\n",
    "print(f\"Learning rate                : {args.learning_rate}\")\n",
    "print(f\"Per-device train batch size  : {args.per_device_train_batch_size}\")\n",
    "print(f\"Weight decay                 : {args.weight_decay}\")\n",
    "print(f\"Warmup steps                 : {args.warmup_steps}\")\n",
    "print(f\"Num train epochs             : {args.num_train_epochs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb646bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Bar chart of final test BLEU:\n",
    "# assume you did: scores = trainer.evaluate(tokenized[\"test\"])\n",
    "test_bleu = scores.get(\"eval_bleu\", scores.get(\"bleu\", 0))\n",
    "plt.figure()\n",
    "plt.bar([\"Test BLEU\"], [test_bleu])\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel(\"BLEU Score\")\n",
    "plt.title(\"Test Set BLEU\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2) Line plot of validation BLEU per epoch:\n",
    "history = trainer.state.log_history\n",
    "# collect BLEU at each evaluation step\n",
    "val_bleus = [x[\"eval_bleu\"] for x in history if \"eval_bleu\" in x]\n",
    "epochs = list(range(1, len(val_bleus) + 1))\n",
    "plt.figure()\n",
    "plt.plot(epochs, val_bleus, marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"BLEU\")\n",
    "plt.title(\"Validation BLEU per Epoch\")\n",
    "plt.xticks(epochs)\n",
    "plt.ylim(0, max(val_bleus) * 1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d55b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
